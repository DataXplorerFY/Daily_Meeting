{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75d26d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import cvzone\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter  # Import Counter from collections module\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aa5b24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('./runs/detect/train/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4f1a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_file = open(\"coco.txt\", \"r\")\n",
    "# data = my_file.read()\n",
    "# class_list = data.split(\"\\n\")\n",
    "\n",
    "def object(img):\n",
    "    results = model.predict(img)\n",
    "    a = results[0].boxes.data\n",
    "    px = pd.DataFrame(a).astype(\"float\")\n",
    "    object_classes = []\n",
    "\n",
    "    for index, row in px.iterrows():\n",
    "        x1=int(row[0])\n",
    "        y1=int(row[1])\n",
    "        x2=int(row[2])\n",
    "        y2=int(row[3])\n",
    "        conf = float(row[4])# Get confidence score from column 4\n",
    "        d=int(row[5])\n",
    "#         c=class_list[d]\n",
    "        obj_class = \"orange\" #class_list[d]\n",
    "        \n",
    "        # Show confidence score with two decimal places\n",
    "        confidence_text = f\"{obj_class}: {conf:.2f}\"\n",
    "        \n",
    "        \n",
    "        # Adjust bounding box and text parameters based on the image and your preferences\n",
    "        bounding_box_color = (0, 0, 255)  # Red color for the first bounding box\n",
    "        text_color = (255, 255, 255)  # White color for text\n",
    "        text_font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        text_size = 1\n",
    "        text_thickness = 2\n",
    "        text_offset_x = 5  # Adjust horizontal offset for text within box\n",
    "        text_offset_y = 5  # Adjust vertical offset for text within box\n",
    "\n",
    "        # Draw bounding box with adjusted color\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), bounding_box_color, 2)\n",
    "\n",
    "        # Calculate text dimensions for background rectangle\n",
    "        (text_width, text_height) = cv2.getTextSize(confidence_text, text_font, text_size, text_thickness)[0]\n",
    "        text_background_width = text_width + 2 * text_offset_x  # Add some padding\n",
    "        text_background_height = text_height + 2 * text_offset_y\n",
    "\n",
    "        # Draw background rectangle with adjusted color\n",
    "        cv2.rectangle(img, (x1, y1 - text_background_height), (x1 + text_background_width, y1), bounding_box_color, -1)  # Filled rectangle\n",
    "\n",
    "        # Display class and confidence score within the box using adjusted parameters\n",
    "        text_x = x1 + text_offset_x\n",
    "        text_y = y1 - text_offset_y  # Adjust y-coordinate for text placement within box\n",
    "        cv2.putText(img, confidence_text, (text_x, text_y), text_font, text_size, text_color, text_thickness)\n",
    "        object_classes.append(obj_class)\n",
    "        \n",
    "#         # Change bounding box color to red\n",
    "#         cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)        \n",
    "#         # Display class and confidence score as text within the box\n",
    "#         cv2.putText(img, confidence_text, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 1, cv2.LINE_AA) # White text\n",
    "#         #cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 2)\n",
    "#         #cvzone.putTextRect(img, f'{obj_class}', (x2, y2), 1, 1)\n",
    "\n",
    "    return object_classes\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25ad7be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_objects_in_image(object_classes):\n",
    "    counter = Counter(object_classes)\n",
    "    print(\"Object Count in Image:\")\n",
    "    for obj, count in counter.items():\n",
    "        print(f\"{obj}s: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fa7c3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 31 oranges, 178.5ms\n",
      "Speed: 14.4ms preprocess, 178.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Object Count in Image:\n",
      "oranges: 31\n"
     ]
    }
   ],
   "source": [
    "path = \"./Test Images/1.jpg\"\n",
    "for file in glob.glob(path):\n",
    "    img = cv2.imread(file)\n",
    "    img = cv2.resize(img, (640, 640))\n",
    "    object_classes = object(img)\n",
    "    count_objects_in_image(object_classes)\n",
    "    cv2.imshow(\"img\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8659b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c33aeba",
   "metadata": {},
   "source": [
    "# scikit-learn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a14e70",
   "metadata": {},
   "source": [
    "Evaluate several classifiers on the Wine dataset using scikit-learn\n",
    "\n",
    "Ratio 60-40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e210943f",
   "metadata": {},
   "source": [
    "# Svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e147978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy on Test Set: 0.6805555555555556\n",
      "SVM Accuracy on Training Set: 0.6698113207547169\n",
      "SVM Cross-Validation Scores: [0.63888889 0.61111111 0.63888889 0.68571429 0.74285714]\n",
      "------------------------------------------------------------\n",
      "SVM Cross-Validation Scores: 0.657532956685499\n",
      "------------------------------------------------------------\n",
      "SVM Cross-Validation Scores: 0.6525274725274725\n",
      "------------------------------------------------------------\n",
      "SVM Cross-Validation Scores percentage : [63.88888889 61.11111111 63.88888889 68.57142857 74.28571429]\n",
      "SVM Cross-Validation Mean Score: 0.6634920634920635\n",
      "SVM Cross-Validation Standard Deviation: 0.04636170738133653\n",
      "------------------------------------------------------------\n",
      "SVM Cross-Validation Standard Deviation: 0.032039704709751565\n",
      "------------------------------------------------------------\n",
      "SVM Cross-Validation Standard Deviation: 0.06582041486989956\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.6)\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "clf_svm = svm.SVC()\n",
    "clf_svm.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "svm_acc_test = clf_svm.score(x_test, y_test)\n",
    "svm_acc_train = clf_svm.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_svm = cross_val_score(clf_svm, x, y, cv=5)\n",
    "cv_svm3 = cross_val_score(clf_svm, x, y, cv=3)\n",
    "cv_svm7 = cross_val_score(clf_svm, x, y, cv=7)\n",
    "# Printing Results\n",
    "print(\"SVM Accuracy on Test Set:\", svm_acc_test)\n",
    "print(\"SVM Accuracy on Training Set:\", svm_acc_train)\n",
    "print(\"SVM Cross-Validation Scores:\", cv_svm)\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"SVM Cross-Validation Scores:\", cv_svm3.mean())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"SVM Cross-Validation Scores:\", cv_svm7.mean())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"SVM Cross-Validation Scores percentage :\", cv_svm * 100)\n",
    "print(\"SVM Cross-Validation Mean Score:\", cv_svm.mean())\n",
    "print(\"SVM Cross-Validation Standard Deviation:\", cv_svm.std())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"SVM Cross-Validation Standard Deviation:\", cv_svm3.std())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"SVM Cross-Validation Standard Deviation:\", cv_svm7.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11fc50f",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b6ab4ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy on Test Set: 0.9583333333333334\n",
      "Decision Tree Accuracy on Training Set: 1.0\n",
      "Decision Tree Cross-Validation Scores: [0.94444444 0.83333333 0.86111111 0.91428571 0.85714286]\n",
      "------------------------------------------------------------\n",
      "Decision Tree Cross-Validation Scores: 0.9042372881355932\n",
      "------------------------------------------------------------\n",
      "Decision Tree Cross-Validation Scores: 0.8824175824175823\n",
      "------------------------------------------------------------\n",
      "Decision Tree-Validation Scores percentage : [63.88888889 61.11111111 63.88888889 68.57142857 74.28571429]\n",
      "Decision Tree-Validation Mean Score: 0.882063492063492\n",
      "Decision Tree Cross-Validation Standard Deviation: 0.0409006687162463\n",
      "------------------------------------------------------------\n",
      "Decision Tree-Validation Standard Deviation: 0.05263796662125264\n",
      "------------------------------------------------------------\n",
      "Decision Tree-Validation Standard Deviation: 0.05878371113739871\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.6)\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "dt_acc_test = dt.score(x_test, y_test)\n",
    "dt_acc_train = dt.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_dt = cross_val_score(dt, x, y, cv=5)\n",
    "cv_dt3 = cross_val_score(dt, x, y, cv=3)\n",
    "cv_dt7= cross_val_score(dt, x, y, cv=7)\n",
    "\n",
    "\n",
    "# Printing Results\n",
    "print(\"Decision Tree Accuracy on Test Set:\", dt_acc_test)\n",
    "print(\"Decision Tree Accuracy on Training Set:\", dt_acc_train)\n",
    "print(\"Decision Tree Cross-Validation Scores:\", cv_dt)\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Decision Tree Cross-Validation Scores:\", cv_dt3.mean())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Decision Tree Cross-Validation Scores:\", cv_dt7.mean())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Decision Tree-Validation Scores percentage :\", cv_svm * 100)\n",
    "print(\"Decision Tree-Validation Mean Score:\", cv_dt.mean())\n",
    "print(\"Decision Tree Cross-Validation Standard Deviation:\", cv_dt.std())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Decision Tree-Validation Standard Deviation:\", cv_dt3.std())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Decision Tree-Validation Standard Deviation:\", cv_dt7.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f531b6",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f72c04df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy on Test Set: 0.9583333333333334\n",
      "Random Forest Accuracy on Training Set: 1.0\n",
      "Random Forest Cross-Validation Scores: [0.97222222 0.94444444 1.         0.97142857 1.        ]\n",
      "Random Forest -Validation Scores percentage : [ 97.22222222  94.44444444 100.          97.14285714 100.        ]\n",
      "Random Forest -Validation Mean Score: 0.9776190476190475\n",
      "------------------------------------------------------------\n",
      "Random Forest -Validation Scores: 0.9494350282485876\n",
      "------------------------------------------------------------\n",
      "Random Forest -Validation Scores: 0.9725274725274725\n",
      "------------------------------------------------------------\n",
      "Random Forest Cross-Validation Standard Deviation: 0.020831783767013237\n",
      "------------------------------------------------------------\n",
      "Random Forest Cross-Validation Standard Deviation: 0.027680733160189507\n",
      "------------------------------------------------------------\n",
      "Random Forest -Validation Standard Deviation: 0.039621442587516376\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.6)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "rf_acc_test = rf.score(x_test, y_test)\n",
    "rf_acc_train = rf.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_rf = cross_val_score(rf, x, y, cv=5)\n",
    "cv_rf3 = cross_val_score(rf, x, y, cv=3)\n",
    "cv_rf7 = cross_val_score(rf, x, y, cv=7)\n",
    "# Printing Results\n",
    "print(\"Random Forest Accuracy on Test Set:\", rf_acc_test)\n",
    "print(\"Random Forest Accuracy on Training Set:\", rf_acc_train)\n",
    "print(\"Random Forest Cross-Validation Scores:\", cv_rf)\n",
    "print(\"Random Forest -Validation Scores percentage :\", cv_rf * 100)\n",
    "print(\"Random Forest -Validation Mean Score:\", cv_rf.mean())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Random Forest -Validation Scores:\", cv_rf3.mean())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Random Forest -Validation Scores:\", cv_rf7.mean())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Random Forest Cross-Validation Standard Deviation:\", cv_rf.std())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Random Forest Cross-Validation Standard Deviation:\", cv_rf3.std())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Random Forest -Validation Standard Deviation:\", cv_rf7.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acff8afb",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5a8bff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy on Test Set: 0.9305555555555556\n",
      "Logistic Regression Accuracy on Training Set: 0.9905660377358491\n",
      "Logistic Regression Cross-Validation Scores: [0.88888889 0.94444444 0.94444444 1.         1.        ]\n",
      "Logistic Regression -Validation Mean Score: 0.9555555555555555\n",
      "------------------------------------------------------------\n",
      "Logistic Regression -Validation Scores: 0.9052730696798493\n",
      "------------------------------------------------------------\n",
      "Logistic Regression -Validation Scores: 0.945054945054945\n",
      "------------------------------------------------------------\n",
      "Logistic Regression Cross-Validation Standard Deviation: 0.041573970964154924\n",
      "------------------------------------------------------------\n",
      "Logistic Regression Cross-Validation Standard Deviation: 0.1001837219112134\n",
      "------------------------------------------------------------\n",
      "Logistic Regression -Validation Standard Deviation: 0.06454582485972929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.6)\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "lr_acc_test = lr.score(x_test, y_test)\n",
    "lr_acc_train = lr.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_lr = cross_val_score(lr, x, y, cv=5)\n",
    "cv_lr3 = cross_val_score(lr, x, y, cv=3)\n",
    "cv_lr7 = cross_val_score(lr, x, y, cv=7)\n",
    "# Printing Results\n",
    "print(\"Logistic Regression Accuracy on Test Set:\", lr_acc_test)\n",
    "print(\"Logistic Regression Accuracy on Training Set:\", lr_acc_train)\n",
    "print(\"Logistic Regression Cross-Validation Scores:\", cv_lr)\n",
    "print(\"Logistic Regression -Validation Mean Score:\", cv_lr.mean())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Logistic Regression -Validation Scores:\", cv_lr3.mean())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Logistic Regression -Validation Scores:\", cv_lr7.mean())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Logistic Regression Cross-Validation Standard Deviation:\", cv_lr.std())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Logistic Regression Cross-Validation Standard Deviation:\", cv_lr3.std())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Logistic Regression -Validation Standard Deviation:\", cv_lr7.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b2e85e",
   "metadata": {},
   "source": [
    "# GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72f3e88a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy on Test Set: 0.9444444444444444\n",
      "Naive Bayes Accuracy on Training Set: 0.9905660377358491\n",
      "Naive Bayes Cross-Validation Scores: [0.94444444 0.97222222 0.97222222 0.94285714 1.        ]\n",
      "Naive Bayes -Validation Mean Score: 0.9663492063492063\n",
      "------------------------------------------------------------\n",
      "Naive Bayes -Validation mean Scores: 0.9607344632768361\n",
      "------------------------------------------------------------\n",
      "Naive Bayes -Validation mean Scores: 0.9613186813186813\n",
      "------------------------------------------------------------\n",
      "Naive Bayes Cross-Validation Standard Deviation: 0.02113317858457236\n",
      "------------------------------------------------------------\n",
      "Naive Bayes Cross-Validation Standard Deviation: 0.007590411775448826\n",
      "------------------------------------------------------------\n",
      "Naive Bayes-Validation Standard Deviation: 0.03561253468224893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.6)\n",
    "\n",
    "# Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "nb_acc_test = nb.score(x_test, y_test)\n",
    "nb_acc_train = nb.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_nb = cross_val_score(nb, x, y, cv=5)\n",
    "cv_nb3 = cross_val_score(nb, x, y, cv=3)\n",
    "cv_nb7 = cross_val_score(nb, x, y, cv=7)\n",
    "\n",
    "# Printing Results\n",
    "print(\"Naive Bayes Accuracy on Test Set:\", nb_acc_test)\n",
    "print(\"Naive Bayes Accuracy on Training Set:\", nb_acc_train)                          \n",
    "print(\"Naive Bayes Cross-Validation Scores:\", cv_nb)\n",
    "print(\"Naive Bayes -Validation Mean Score:\", cv_nb.mean())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Naive Bayes -Validation mean Scores:\", cv_nb3.mean())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Naive Bayes -Validation mean Scores:\", cv_nb7.mean())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Naive Bayes Cross-Validation Standard Deviation:\", cv_nb.std())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Naive Bayes Cross-Validation Standard Deviation:\", cv_nb3.std())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Naive Bayes-Validation Standard Deviation:\", cv_nb7.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309d5120",
   "metadata": {},
   "source": [
    "# K Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e5e34ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Accuracy on Test Set: 0.6666666666666666\n",
      "K-Nearest Neighbors Accuracy on Training Set: 0.8018867924528302\n",
      "K-Nearest Neighbors Cross-Validation Scores: [0.72222222 0.66666667 0.63888889 0.65714286 0.77142857]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.6)\n",
    "\n",
    "# K-Nearest Neighbors (KNN)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "knn_acc_test = knn.score(x_test, y_test)\n",
    "knn_acc_train = knn.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_knn = cross_val_score(knn, x, y, cv=5)\n",
    "cv_knn3 = cross_val_score(knn, x, y, cv=3)\n",
    "cv_knn7 = cross_val_score(knn, x, y, cv=7)\n",
    "\n",
    "\n",
    "# Printing Results\n",
    "print(\"K-Nearest Neighbors Accuracy on Test Set:\", knn_acc_test)\n",
    "print(\"K-Nearest Neighbors Accuracy on Training Set:\", knn_acc_train)\n",
    "print(\"K-Nearest Neighbors Cross-Validation Scores:\", cv_knn)\n",
    "print(\"K-Nearest Neighbors-Validation Mean Score:\", cv_knn.mean())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"K-Nearest Neighbors-Validation mean Scores:\", cv_knn3.mean())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"K-Nearest Neighbors-Validation mean Scores:\", cv_knn7.mean())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"K-Nearest Neighbors-Validation Standard Deviation:\", cv_knn.std())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"K-Nearest Neighbors Cross-Validation Standard Deviation:\", cv_knn3.std())\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(\"Naive Bayes-Validation Standard Deviation:\", cv_knn7.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cca69d",
   "metadata": {},
   "source": [
    "# AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1395f0d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.6)\n",
    "\n",
    "# AdaBoost\n",
    "adaboost = AdaBoostClassifier()\n",
    "adaboost.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "adaboost_acc_test = adaboost.score(x_test, y_test)\n",
    "adaboost_acc_train = adaboost.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_adaboost = cross_val_score(adaboost, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"AdaBoost Accuracy on Test Set:\", adaboost_acc_test)\n",
    "print(\"AdaBoost Accuracy on Training Set:\", adaboost_acc_train)\n",
    "print(\"AdaBoost Cross-Validation Scores:\", cv_adaboost)\n",
    "print(\"AdaBoost Cross-Validation Mean Score:\", cv_adaboost.mean())\n",
    "print(\"AdaBoost Cross-Validation Standard Deviation:\", cv_adaboost.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e06fc2",
   "metadata": {},
   "source": [
    "# Ratio 70-30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1233df",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20adc454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.7)\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "clf_svm = SVC()\n",
    "clf_svm.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "svm_acc_test = clf_svm.score(x_test, y_test)\n",
    "svm_acc_train = clf_svm.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_svm = cross_val_score(clf_svm, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"SVM Accuracy on Test Set:\", svm_acc_test)\n",
    "print(\"SVM Accuracy on Training Set:\", svm_acc_train)\n",
    "print(\"SVM Cross-Validation Scores:\", cv_svm)\n",
    "print(\"SVM Cross-Validation Scores percentage :\", cv_svm * 100)\n",
    "print(\"SVM Cross-Validation Mean Score:\", cv_svm.mean())\n",
    "print(\"SVM Cross-Validation Standard Deviation:\", cv_svm.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfca89ae",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fd576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.7)\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "dt_acc_test = dt.score(x_test, y_test)\n",
    "dt_acc_train = dt.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_dt = cross_val_score(dt, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"Decision Tree Accuracy on Test Set:\", dt_acc_test)\n",
    "print(\"Decision Tree Accuracy on Training Set:\", dt_acc_train)\n",
    "print(\"Decision Tree Cross-Validation Scores:\", cv_dt)\n",
    "print(\"Decision Tree Cross-Validation Mean Score:\", cv_dt.mean())\n",
    "print(\"Decision Tree Cross-Validation Standard Deviation:\", cv_dt.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8a1ac9",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f50bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.7)\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "lr_acc_test = lr.score(x_test, y_test)\n",
    "lr_acc_train = lr.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_lr = cross_val_score(lr, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"Logistic Regression Accuracy on Test Set:\", lr_acc_test)\n",
    "print(\"Logistic Regression Accuracy on Training Set:\", lr_acc_train)\n",
    "print(\"Logistic Regression Cross-Validation Scores:\", cv_lr)\n",
    "print(\"Logistic Regression Cross-Validation Mean Score:\", cv_lr.mean())\n",
    "print(\"Logistic Regression Cross-Validation Standard Deviation:\", cv_lr.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcea92de",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0431b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.7)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "rf_acc_test = rf.score(x_test, y_test)\n",
    "rf_acc_train = rf.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_rf = cross_val_score(rf, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"Random Forest Accuracy on Test Set:\", rf_acc_test)\n",
    "print(\"Random Forest Accuracy on Training Set:\", rf_acc_train)\n",
    "print(\"Random Forest Cross-Validation Scores:\", cv_rf)\n",
    "print(\"Random Forest Cross-Validation Mean Score:\", cv_rf.mean())\n",
    "print(\"Random Forest Cross-Validation Standard Deviation:\", cv_rf.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb40b077",
   "metadata": {},
   "source": [
    "# GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4dca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.7)\n",
    "\n",
    "# Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "nb_acc_test = nb.score(x_test, y_test)\n",
    "nb_acc_train = nb.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_nb = cross_val_score(nb, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"Naive Bayes Accuracy on Test Set:\", nb_acc_test)\n",
    "print(\"Naive Bayes Accuracy on Training Set:\", nb_acc_train)\n",
    "print(\"Naive Bayes Cross-Validation Scores:\", cv_nb)\n",
    "print(\"Naive Bayes Cross-Validation Mean Score:\", cv_nb.mean())\n",
    "print(\"Naive Bayes Cross-Validation Standard Deviation:\", cv_nb.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3033a33",
   "metadata": {},
   "source": [
    "# KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f10394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.7)\n",
    "\n",
    "# K-Nearest Neighbors (KNN)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "knn_acc_test = knn.score(x_test, y_test)\n",
    "knn_acc_train = knn.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_knn = cross_val_score(knn, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"K-Nearest Neighbors Accuracy on Test Set:\", knn_acc_test)\n",
    "print(\"K-Nearest Neighbors Accuracy on Training Set:\", knn_acc_train)\n",
    "print(\"K-Nearest Neighbors Cross-Validation Scores:\", cv_knn)\n",
    "print(\"K-Nearest Neighbors Cross-Validation Mean Score:\", cv_knn.mean())\n",
    "print(\"K-Nearest Neighbors Cross-Validation Standard Deviation:\", cv_knn.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf5bae7",
   "metadata": {},
   "source": [
    "# AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225acae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.7)\n",
    "\n",
    "# AdaBoost\n",
    "adaboost = AdaBoostClassifier()\n",
    "adaboost.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "adaboost_acc_test = adaboost.score(x_test, y_test)\n",
    "adaboost_acc_train = adaboost.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_adaboost = cross_val_score(adaboost, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"AdaBoost Accuracy on Test Set:\", adaboost_acc_test)\n",
    "print(\"AdaBoost Accuracy on Training Set:\", adaboost_acc_train)\n",
    "print(\"AdaBoost Cross-Validation Scores:\", cv_adaboost)\n",
    "print(\"AdaBoost Cross-Validation Mean Score:\", cv_adaboost.mean())\n",
    "print(\"AdaBoost Cross-Validation Standard Deviation:\", cv_adaboost.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e974d76",
   "metadata": {},
   "source": [
    "# With Ratio 80 - 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6f1d8c",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5514a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.8)\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "clf_svm = SVC()\n",
    "clf_svm.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "svm_acc_test = clf_svm.score(x_test, y_test)\n",
    "svm_acc_train = clf_svm.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_svm = cross_val_score(clf_svm, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"SVM Accuracy on Test Set:\", svm_acc_test)\n",
    "print(\"SVM Accuracy on Training Set:\", svm_acc_train)\n",
    "print(\"SVM Cross-Validation Scores:\", cv_svm)\n",
    "print(\"SVM Cross-Validation Scores percentage :\", cv_svm * 100)\n",
    "print(\"SVM Cross-Validation Mean Score:\", cv_svm.mean())\n",
    "print(\"SVM Cross-Validation Standard Deviation:\", cv_svm.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de6dfb0",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f312e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.8)\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "dt_acc_test = dt.score(x_test, y_test)\n",
    "dt_acc_train = dt.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_dt = cross_val_score(dt, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"Decision Tree Accuracy on Test Set:\", dt_acc_test)\n",
    "print(\"Decision Tree Accuracy on Training Set:\", dt_acc_train)\n",
    "print(\"Decision Tree Cross-Validation Scores:\", cv_dt)\n",
    "print(\"Decision Tree Cross-Validation Mean Score:\", cv_dt.mean())\n",
    "print(\"Decision Tree Cross-Validation Standard Deviation:\", cv_dt.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7172c44",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbddcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.8)\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "lr_acc_test = lr.score(x_test, y_test)\n",
    "lr_acc_train = lr.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_lr = cross_val_score(lr, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"Logistic Regression Accuracy on Test Set:\", lr_acc_test)\n",
    "print(\"Logistic Regression Accuracy on Training Set:\", lr_acc_train)\n",
    "print(\"Logistic Regression Cross-Validation Scores:\", cv_lr)\n",
    "print(\"Logistic Regression Cross-Validation Mean Score:\", cv_lr.mean())\n",
    "print(\"Logistic Regression Cross-Validation Standard Deviation:\", cv_lr.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b05c21a",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a7859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.8)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "rf_acc_test = rf.score(x_test, y_test)\n",
    "rf_acc_train = rf.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_rf = cross_val_score(rf, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"Random Forest Accuracy on Test Set:\", rf_acc_test)\n",
    "print(\"Random Forest Accuracy on Training Set:\", rf_acc_train)\n",
    "print(\"Random Forest Cross-Validation Scores:\", cv_rf)\n",
    "print(\"Random Forest Cross-Validation Mean Score:\", cv_rf.mean())\n",
    "print(\"Random Forest Cross-Validation Standard Deviation:\", cv_rf.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055baa63",
   "metadata": {},
   "source": [
    "# GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fc19b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.8)\n",
    "\n",
    "# Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "nb_acc_test = nb.score(x_test, y_test)\n",
    "nb_acc_train = nb.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_nb = cross_val_score(nb, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"Naive Bayes Accuracy on Test Set:\", nb_acc_test)\n",
    "print(\"Naive Bayes Accuracy on Training Set:\", nb_acc_train)\n",
    "print(\"Naive Bayes Cross-Validation Scores:\", cv_nb)\n",
    "print(\"Naive Bayes Cross-Validation Mean Score:\", cv_nb.mean())\n",
    "print(\"Naive Bayes Cross-Validation Standard Deviation:\", cv_nb.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e798bb69",
   "metadata": {},
   "source": [
    "# KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf6790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.8)\n",
    "\n",
    "# K-Nearest Neighbors (KNN)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "knn_acc_test = knn.score(x_test, y_test)\n",
    "knn_acc_train = knn.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_knn = cross_val_score(knn, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"K-Nearest Neighbors Accuracy on Test Set:\", knn_acc_test)\n",
    "print(\"K-Nearest Neighbors Accuracy on Training Set:\", knn_acc_train)\n",
    "print(\"K-Nearest Neighbors Cross-Validation Scores:\", cv_knn)\n",
    "print(\"K-Nearest Neighbors Cross-Validation Mean Score:\", cv_knn.mean())\n",
    "print(\"K-Nearest Neighbors Cross-Validation Standard Deviation:\", cv_knn.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f2c6c8",
   "metadata": {},
   "source": [
    "# AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad78819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Loading the dataset\n",
    "x, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, train_size=0.8)\n",
    "\n",
    "# AdaBoost\n",
    "adaboost = AdaBoostClassifier()\n",
    "adaboost.fit(x_train, y_train)\n",
    "\n",
    "# Accuracy Scores\n",
    "adaboost_acc_test = adaboost.score(x_test, y_test)\n",
    "adaboost_acc_train = adaboost.score(x_train, y_train)\n",
    "\n",
    "# Cross-Validation\n",
    "cv_adaboost = cross_val_score(adaboost, x, y, cv=5)\n",
    "\n",
    "# Printing Results\n",
    "print(\"AdaBoost Accuracy on Test Set:\", adaboost_acc_test)\n",
    "print(\"AdaBoost Accuracy on Training Set:\", adaboost_acc_train)\n",
    "print(\"AdaBoost Cross-Validation Scores:\", cv_adaboost)\n",
    "print(\"AdaBoost Cross-Validation Mean Score:\", cv_adaboost.mean())\n",
    "print(\"AdaBoost Cross-Validation Standard Deviation:\", cv_adaboost.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b48b812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29500903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
